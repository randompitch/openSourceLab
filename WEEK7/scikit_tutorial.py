# -*- coding: utf-8 -*-
"""SciKit Tutorial.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18aGykX5_KUvzuyuQD6FKdmjeD09Dgs5I
"""

import pandas as pd

columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital',  'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_week', 'native_country','label']

features = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital',  'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_week', 'native_country']

path ="https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"

df_train = pd.read_csv(path, skipinitialspace=True, names = columns, index_col =  False)



df_train.head()

# List continuous features
cont_features = df_train._get_numeric_data()
print(cont_features)
print(cont_features.columns)
print(len(cont_features.columns))

# list the categorical features
cate_features = df_train.select_dtypes('object')
print(cate_features.columns)
print(len(cate_features.columns))

# converting cont features to float format
df_train[cont_features.columns] = df_train[cont_features.columns].astype("float64")

print(df_train[cont_features.columns])

# this give description only of cont features
df_train.describe()

# for description of all featuers
df_train.describe(include = 'all')



# get the column index of cat features
categoricals = []
for i in cate_features:
  pos = df_train.columns.get_loc(i)
  categoricals.append(pos)

print(categoricals)

# get the column index of cont features
continous = []
for i in cont_features:
  pos = df_train.columns.get_loc(i)
  continous.append(pos)

print(continous)



# CONVERTING CATE FEATURES TO CONT VALUES USING ENCODERS
from sklearn import preprocessing
le = preprocessing.LabelEncoder()
print(cate_features)

df_train['workclass'] = le.fit_transform(df_train['workclass'])
df_train['education'] = le.fit_transform(df_train['education'])
df_train['marital'] = le.fit_transform(df_train['marital'])
df_train['occupation'] = le.fit_transform(df_train['occupation'])
df_train['relationship'] = le.fit_transform(df_train['relationship'])
df_train['race'] = le.fit_transform(df_train['race'])
df_train['sex'] = le.fit_transform(df_train['sex'])
df_train['native_country'] = le.fit_transform(df_train['native_country'])

print(cate_features)

from sklearn.impute import SimpleImputer
imp = SimpleImputer(missing_values = 0, strategy = 'mean')
imp.fit_transform(df_train[features])

df_train.head()

# split the data
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df_train[features], df_train['label'], random_state = 0)

print(len(X_train))

# Naive Bayes
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
gnb = GaussianNB()
# train the model
pred  = gnb.fit(X_train, y_train).predict(X_test)

print("Naive Bayes Accuracy: ", accuracy_score(y_test, pred, normalize = True))